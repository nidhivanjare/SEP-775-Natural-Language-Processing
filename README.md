# SEP-775-Natural-Language-Processing
Final Project 


# Sequence-to-Sequence Model with Bahdanau Attention

This project implements a sequence-to-sequence model with Bahdanau attention mechanism for translation tasks. 

## Introduction

Sequence-to-sequence models are a type of neural network architecture that can be used for tasks like machine translation, text summarization, and more. Bahdanau attention is an attention mechanism that allows the model to focus on different parts of the input sequence when generating each part of the output sequence.

This project implements a sequence-to-sequence model with Bahdanau attention using TensorFlow. The model is trained on a dataset of English and Shakespearean sentences to translate Shakespearean sentences to English.

## Dependencies

To run this project, you need the following dependencies:

- Python 3.x
- TensorFlow 2.x
- NumPy
- pandas

To use this project, follow these steps:

1. Clone the repository:

```bash
git clone https://github.com/yourusername/sequence-to-sequence.git
cd Supervised Learning

